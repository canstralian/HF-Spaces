{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1AvRy9k9DvDY7P62xtsja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77fa33e6f9384258b9940ddacadf9a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac086d8878c40de8e0b9cc50b9089c8",
              "IPY_MODEL_00059cd358984aceba49878786c2e857"
            ],
            "layout": "IPY_MODEL_dc991ce8b68142b4a30539c5f116684c"
          }
        },
        "5ac086d8878c40de8e0b9cc50b9089c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9995a09a671743fa9b6f8a3b3a5f8727",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f33480266b444658a5309dbe54d0f3b1",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "00059cd358984aceba49878786c2e857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0675d1afc14a4f4787e9843585d868de",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_109aa5d3136d4eac881376b51fa88a9d",
            "value": 1
          }
        },
        "dc991ce8b68142b4a30539c5f116684c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9995a09a671743fa9b6f8a3b3a5f8727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33480266b444658a5309dbe54d0f3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0675d1afc14a4f4787e9843585d868de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109aa5d3136d4eac881376b51fa88a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canstralian/HF-Spaces/blob/main/Transformers_and_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "jROWwjLhcU8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GeWa0iGTEtn"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas gradio tensorflow torch matplotlib seaborn transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments AutoModel\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login, HfFolder\n",
        "from google.colab import userdata, auth, drive\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "T7A9jg4wjsLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "model = AutoModel.from_pretrained(\"Canstralian/CySec_Known_Exploit_Analyzer\")"
      ],
      "metadata": {
        "id": "vvvOjQCfoQTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_function(input_text):\n",
        "           # Preprocess the input text (e.g., tokenize)\n",
        "           inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "           # Get model predictions\n",
        "           outputs = model(**inputs)\n",
        "           # Postprocess the predictions (e.g., extract the most likely class)\n",
        "           prediction = outputs.logits.argmax(-1).item()\n",
        "           # Return the prediction\n",
        "           return prediction\n",
        "\n",
        "       iface = gr.Interface(\n",
        "           fn=predict_function,\n",
        "           inputs=gr.Textbox(lines=2, placeholder=\"Enter text here...\"),\n",
        "           outputs=\"text\",\n",
        "           title=\"Cybersecurity Exploit Analyzer\",\n",
        "           description=\"Enter text to analyze for potential exploits.\"\n",
        "       )\n",
        "\n",
        "       iface.launch()"
      ],
      "metadata": {
        "id": "wLKPcGQso1gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = widgets.Text(placeholder=\"Enter text here...\")\n",
        "       output_label = widgets.Label()\n",
        "\n",
        "       def predict(change):\n",
        "           input_text = text_input.value\n",
        "           # Preprocess, predict, and postprocess as in the Gradio example\n",
        "           # ...\n",
        "           output_label.value = f\"Prediction: {prediction}\"\n",
        "\n",
        "       text_input.observe(predict, names='value')\n",
        "\n",
        "       display(text_input, output_label)"
      ],
      "metadata": {
        "id": "tCh2RFQCo8tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "# Define metric for evaluation\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    return {\"accuracy\": (preds == labels).mean()}\n",
        "\n",
        "# Update TrainingArguments with early stopping and best model selection\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    metric_for_best_model=\"accuracy\",  # Use accuracy to select the best model\n",
        "    load_best_model_at_end=True,  # Automatically load the best model after training\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with early stopping callback\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],  # Train dataset\n",
        "    eval_dataset=tokenized_dataset[\"test\"],    # Test dataset\n",
        "    compute_metrics=compute_metrics,  # Provide custom metric function\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # Stop training after 3 epochs without improvement\n",
        ")\n",
        "\n",
        "# Start the training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "EKeqyxSdktKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Datasets"
      ],
      "metadata": {
        "id": "jd7HUIKhb0Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the custom dataset\n",
        "ds_wordlists = load_dataset(\"Canstralian/Wordlists\")\n",
        "ds_pentesting = load_dataset(\"Canstralian/pentesting_dataset\")\n",
        "\n",
        "# Display information about the dataset\n",
        "print(\"Wordlists dataset structure:\", ds_wordlists)\n",
        "print(\"Pentesting dataset structure:\", ds_pentesting)\n",
        "\n",
        "# Show the first sample in each dataset\n",
        "print(\"First example from Wordlists dataset:\", ds_wordlists[\"train\"][0])  # Adjust the split name if different\n",
        "print(\"First example from Pentesting dataset:\", ds_pentesting[\"train\"][0])  # Adjust the split name if different"
      ],
      "metadata": {
        "id": "ePcEAgTeUDiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'col1': [1, 2, 3], 'col2': ['a', 'b', 'c']}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "orS_R38YjbVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 'a'], [2, 'b'], [3, 'c']]\n",
        "df = pd.DataFrame(data, columns=['col1', 'col2'])"
      ],
      "metadata": {
        "id": "ghUC-Z8cjdgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([[1, 'a'], [2, 'b'], [3, 'c']])\n",
        "df = pd.DataFrame(data, columns=['col1', 'col2'])"
      ],
      "metadata": {
        "id": "tnqnzg66jfl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the Tokenizer and Model"
      ],
      "metadata": {
        "id": "qcBqn3I6cG01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login, HfFolder\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get your Hugging Face token from Colab's userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "# If HF_TOKEN is not found in userdata, prompt the user to enter it\n",
        "if HF_TOKEN is None:\n",
        "    HF_TOKEN = getpass.getpass(\"Enter your Hugging Face token: \")\n",
        "    # Optionally, you can store the token in userdata for future use:\n",
        "    # userdata.set('HF_TOKEN', HF_TOKEN)\n",
        "\n",
        "# Save the token to Hugging Face folder\n",
        "HfFolder.save_token(HF_TOKEN)\n",
        "\n",
        "# Login to Hugging Face\n",
        "notebook_login()\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "AdNgAX4WUcGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('Your spreadsheet name').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "print(rows)\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "pd.DataFrame.from_records(rows)"
      ],
      "metadata": {
        "id": "pjASEJvFgwy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained(\"my_fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"my_fine_tuned_model\")\n"
      ],
      "metadata": {
        "id": "pq_GDQyVUnJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"my_fine_tuned_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"my_fine_tuned_model\")\n"
      ],
      "metadata": {
        "id": "BQk5XpabUpHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "jwysvQEscNQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "80nPOFumTthm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "# Replace `ds_wordlists` with `ds_pentesting` if you want to tokenize that dataset instead\n",
        "tokenized_dataset = ds_wordlists.map(tokenize_function, batched=True)\n",
        "\n",
        "# If you're working with a different dataset, replace `ds_wordlists` with the appropriate one"
      ],
      "metadata": {
        "id": "q_LuiclZUgw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with the model, arguments, and data\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],  # This line is fine now\n",
        "    eval_dataset=tokenized_dataset[\"test\"],    # Add a comma here to separate arguments\n",
        ")\n",
        "\n",
        "# Start the training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "77fa33e6f9384258b9940ddacadf9a07",
            "5ac086d8878c40de8e0b9cc50b9089c8",
            "00059cd358984aceba49878786c2e857",
            "dc991ce8b68142b4a30539c5f116684c",
            "9995a09a671743fa9b6f8a3b3a5f8727",
            "f33480266b444658a5309dbe54d0f3b1",
            "0675d1afc14a4f4787e9843585d868de",
            "109aa5d3136d4eac881376b51fa88a9d"
          ]
        },
        "id": "nPWi2smJUlLa",
        "outputId": "3cf5b40a-4b96-4eca-ffb7-4cfea04b68c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77fa33e6f9384258b9940ddacadf9a07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111364677777197, max=1.0)â€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241111_092548-c72t9i6a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dotcomhunters-dotcomhunters/huggingface/runs/c72t9i6a' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/dotcomhunters-dotcomhunters/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dotcomhunters-dotcomhunters/huggingface' target=\"_blank\">https://wandb.ai/dotcomhunters-dotcomhunters/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dotcomhunters-dotcomhunters/huggingface/runs/c72t9i6a' target=\"_blank\">https://wandb.ai/dotcomhunters-dotcomhunters/huggingface/runs/c72t9i6a</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='69' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  69/9375 1:07:30 < 156:16:12, 0.02 it/s, Epoch 0.02/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 106/9375 1:45:24 < 156:34:57, 0.02 it/s, Epoch 0.03/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}